{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "452bc067-17fc-4323-92cc-560708e11922",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "452bc067-17fc-4323-92cc-560708e11922",
        "outputId": "dc5f278e-f95c-494d-e451-f21b2bf1547a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Analyzing Text ===\n",
            "Input Sentence: We are thrilled to announce that the program Manager of Edunet will be visiting chennai NSTI on the exciting day of 20th June!\n",
            "\n",
            "Tokens:\n",
            "['We', 'are', 'thrilled', 'to', 'announce', 'that', 'the', 'program', 'Manager', 'of', 'Edunet', 'will', 'be', 'visiting', 'chennai', 'NSTI', 'on', 'the', 'exciting', 'day', 'of', '20th', 'June', '!']\n",
            "\n",
            "POS Tags:\n",
            "[('We', 'PRP'), ('are', 'VBP'), ('thrilled', 'VBN'), ('to', 'TO'), ('announce', 'VB'), ('that', 'IN'), ('the', 'DT'), ('program', 'NN'), ('Manager', 'NNP'), ('of', 'IN'), ('Edunet', 'NNP'), ('will', 'MD'), ('be', 'VB'), ('visiting', 'VBG'), ('chennai', 'JJ'), ('NSTI', 'NNP'), ('on', 'IN'), ('the', 'DT'), ('exciting', 'JJ'), ('day', 'NN'), ('of', 'IN'), ('20th', 'CD'), ('June', 'NNP'), ('!', '.')]\n",
            "\n",
            "Named Entities:\n",
            "(S\n",
            "  We/PRP\n",
            "  are/VBP\n",
            "  thrilled/VBN\n",
            "  to/TO\n",
            "  announce/VB\n",
            "  that/IN\n",
            "  the/DT\n",
            "  program/NN\n",
            "  Manager/NNP\n",
            "  of/IN\n",
            "  (GPE Edunet/NNP)\n",
            "  will/MD\n",
            "  be/VB\n",
            "  visiting/VBG\n",
            "  chennai/JJ\n",
            "  (ORGANIZATION NSTI/NNP)\n",
            "  on/IN\n",
            "  the/DT\n",
            "  exciting/JJ\n",
            "  day/NN\n",
            "  of/IN\n",
            "  20th/CD\n",
            "  June/NNP\n",
            "  !/.)\n",
            "\n",
            "Sentiment Scores:\n",
            "{'neg': 0.0, 'neu': 0.767, 'pos': 0.233, 'compound': 0.75}\n"
          ]
        }
      ],
      "source": [
        "# Module 7 - To perform word tokenization , Pos Tagging and sentiment analysis\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.chunk import ne_chunk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "\n",
        "def setup_nltk():\n",
        "    \"\"\"\n",
        "    Download required NLTK resources if not already present.\n",
        "    \"\"\"\n",
        "    resources = [\n",
        "        'punkt',\n",
        "        'punkt_tab',\n",
        "        'averaged_perceptron_tagger',\n",
        "        'averaged_perceptron_tagger_eng',\n",
        "        'maxent_ne_chunker',\n",
        "        'maxent_ne_chunker_tab',\n",
        "        'words',\n",
        "        'vader_lexicon'\n",
        "    ]\n",
        "    for res in resources:\n",
        "        nltk.download(res, quiet=True)\n",
        "\n",
        "\n",
        "def analyze_text(text):\n",
        "    \"\"\"\n",
        "    Tokenize, POS-tag, NER-chunk, and sentiment-score the given text.\n",
        "    \"\"\"\n",
        "    print(\"\\n=== Analyzing Text ===\")\n",
        "    print(\"Input Sentence:\", text)\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "    print(\"\\nTokens:\")\n",
        "    print(tokens)\n",
        "\n",
        "    # Part-of-Speech Tagging\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    print(\"\\nPOS Tags:\")\n",
        "    print(pos_tags)\n",
        "\n",
        "    # Named-Entity Recognition\n",
        "    chunks = ne_chunk(pos_tags)\n",
        "    print(\"\\nNamed Entities:\")\n",
        "    print(chunks)\n",
        "\n",
        "    # Sentiment Analysis\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    sentiment = sia.polarity_scores(text)\n",
        "    print(\"\\nSentiment Scores:\")\n",
        "    print(sentiment)\n",
        "\n",
        "    return {\n",
        "        'tokens': tokens,\n",
        "        'pos_tags': pos_tags,\n",
        "        'entities': chunks,\n",
        "        'sentiment': sentiment\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 1. Ensure resources are available\n",
        "    setup_nltk()\n",
        "\n",
        "    # 2. Define the sample comment(s)\n",
        "    comments = [\n",
        "        \"We are thrilled to announce that the program Manager of Edunet will be visiting chennai NSTI on the exciting day of 20th June!\"\n",
        "    ]\n",
        "\n",
        "    # 3. Process each comment\n",
        "    for comment in comments:\n",
        "        analyze_text(comment)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2974383f-957b-442e-98de-ea9213a04c2c",
      "metadata": {
        "id": "2974383f-957b-442e-98de-ea9213a04c2c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2629b0e-9212-4588-a09f-10ed95fe3dca",
      "metadata": {
        "id": "a2629b0e-9212-4588-a09f-10ed95fe3dca"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "510dba33-3700-40d2-bc93-df1a5c20abed",
      "metadata": {
        "id": "510dba33-3700-40d2-bc93-df1a5c20abed"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6322fc6a-1672-4cb3-b641-398b2f814049",
      "metadata": {
        "id": "6322fc6a-1672-4cb3-b641-398b2f814049"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "965b1686-be80-4f70-9234-c25207a756c2",
      "metadata": {
        "id": "965b1686-be80-4f70-9234-c25207a756c2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}